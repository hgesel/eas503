{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Week 14. Machine Learning\n",
    "\n",
    "## General Machine Learning Concept\n",
    "\n",
    "* Simplified: in machine learning, a computer is trained to classify new data.\n",
    "Think of it as an input-output device that takes in a number of inputs, and\n",
    "based on the pattern of these inputs, determine the most likely class associated\n",
    "with that data. There two main types of learning strategies.\n",
    "  1. **Supervised learning** where you train the machine using data for which the correct class is known.\n",
    "    * Classification\n",
    "    * Regression\n",
    "  2. **Unsupervised learning** where the classifier itself tries to find patterns within the input data itself. (Biosignal and Medical Image Processing John Semmlow)\n",
    "    * Clustering\n",
    "  3. *Semi-supervised learning*\n",
    "\n",
    "## General Outline of Machine Learning\n",
    "\n",
    "1. Loading Data\n",
    "  - Load toy data included in sklearn\n",
    "  - Download published/annotated data from online\n",
    "  - Generate data with specific statistics to learn how algorithms work\n",
    "2. Preprocessing Data\n",
    "  - Make data zero mean\n",
    "  - Make data unit variance\n",
    "  - Fix range of values\n",
    "  - Deal with missing values\n",
    "  - Map text labels to integer labels (if applicable)\n",
    "3. Dimensionality Reduction of data\n",
    "  - If you use too many features and do not have enough samples, you could over fit.\n",
    "  - So you have to choose the most discriminating few features\n",
    "4. Applying algorithms\n",
    "  - Labeled Data - Supervised\n",
    "  - Non-labeled Data - Unsupervised\n",
    "5. Evaluation\n",
    "  - Receiver Operator Curve\n",
    "    - Sensitivity\n",
    "    - Specificity\n",
    "  - Imbalanced Data\n",
    "    - Example: 95 % one class, 5% another class\n",
    "\n",
    "## Scikit-learn (sklearn)\n",
    "- Ref: https://scikit-learn.org/\n",
    "- Ref: https://jakevdp.github.io/PythonDataScienceHandbook/index.html\n",
    "- REF: Scikit-learn Essentials: Mastering the scikit-learn Machine Learning Library for Python by Dhiraj Kumar\n",
    "\n",
    "## Various Python Libraries: When to use what\n",
    "  - ref:https://www.quora.com/What-is-the-relationship-among-NumPy-SciPy-Pandas-and-Scikit-learn-and-when-should-I-use-each-one-of-them\n",
    "  - Numpy -- provides efficient array computation via vectorization and broadcasting\n",
    "      - Vectorization -- no need for explicit looping -- example, vector multiplication or squaring\n",
    "      - Broadcasting -- manipulate multiple values at once\n",
    "  - Pandas - Uses Numpy arrays as the underlying structure. Good for analyzing tabular data\n",
    "  - Scipy (scientific python)- provides libraries for scientific computing, including: integration, interpolation, signal processing, linear algebra, statistics. Also uses Numpy infrastructure\n",
    "  - Scikit-learn - provides a collection of machine-learning algorithms that use Numpy and Scipy\n",
    "    - Most used Python library for machine-learning\n",
    "      - regression\n",
    "      - classification\n",
    "      - clustering\n",
    "\n",
    "## Topics Covered\n",
    "  - Introduction to Scikit-learn\n",
    "  - Loading Dataset using Scikit-learn\n",
    "  - Preprocessing data using scikit-learn\n",
    "  - Train Test split using scikit-learn\n",
    "  - Linear regression using scikit-learn\n",
    "  - Naive Bays using Scikit learn\n",
    "  - SVM using Scikit learn\n",
    "  - k-Nearest neighbor using Scikit-learn\n",
    "\n",
    "## Introduction to Scikit-learn\n",
    "  - Choose the right estimator -- the right algorithm for doing ML\n",
    "    - https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "  - Consistent -- all object share a common interface\n",
    "  - Inspection -- all parameter values are exposed as public attributes\n",
    "  - Limited object Hierarchy -- algorithms are represented as Python classes, datasets mainly as numpy array and parameters as standard python strings\n",
    "  - Composition -- ML as a sequences of fundamental algorithms\n",
    "  - Defaults -- provides good default values\n",
    "\n",
    "### High Level Steps\n",
    "  - Choose the class of model to be coded\n",
    "  - Choose the hyper parameters of the model\n",
    "  - Arrange data into target and features\n",
    "  - Write model fitment code using fit() method.\n",
    "\n",
    "### General Steps\n",
    "  - Load Data\n",
    "    - Three ways load data\n",
    "      - Dataset loaders (toy datasets that come with skikit-learn)\n",
    "        - Good for illustrating how the various algorithms work\n",
    "      - Dataset fetchers (real world datasets)\n",
    "        - Built-in functions to load large datasets\n",
    "        - Pull from openml.org\n",
    "      - Dataset generation functions\n",
    "        - Artificial datasets -- can create labeled datasets\n",
    "        -\n",
    "  - Pre-process Data\n",
    "    - Remove mean **\n",
    "    - Scale Variance **\n",
    "    - Non-linear transformation\n",
    "    - Normalization\n",
    "    - Encoding categorical features\n",
    "    - Discretization\n",
    "    - Imputation of missing values\n",
    "    - Maybe remove outliers if it can be justified. Always document this in research paper\n",
    "\n",
    "### Loading data\n",
    "\n",
    "### Preprocessing\n",
    "#### Mean and Variance\n",
    "- algorithms require that all the features have variance of similar magnitude. If the magnitude differ by orders of magnitude larger than others, it might dominate the objective function.\n",
    "  - Whatever mean or std you subtract from the training set, you have to use the same on the testing set.\n",
    "- Algorithms assume that the input data is Gaussian distribution with zero mean and unit variance.\n",
    "- Power transformers aim to map data from any distribution to as close to a Gaussian distribution\n",
    "\n",
    "#### Encoding\n",
    "- Map text values to integer codes. Instead of using text for city names, use integers. Or Male = 0, Female = 1.\n",
    "\n",
    "#### Discretization\n",
    "- Turn continuous values in to discrete values. You bin the continuous into bins. *** Linear models can become non-linear due to discretization\n",
    "\n",
    "\n",
    "#### Imputation\n",
    "- Many real world datasets contain missing values;\n",
    "  - Discard entire rows\n",
    "  - Or fill data -- usually by guessing from available data\n",
    "\n",
    "\n",
    "### Splitting Data\n",
    "- It is common to split data into training and testing samples.\n",
    "- Usually you do 90/10 or 80/20 or 75/25 or 60/40.\n",
    "- The splitting has to be random\n",
    "- Check that distribution features\n",
    "- K-Cross-fold validation -- split data K times\n",
    "\n",
    "### Linear Regression\n",
    "- LR models the relationship between a dependent variable and one or more independent variable. When one increase or decrease, the other increases or decreases.\n",
    "\n",
    "### Naive Bayes\n",
    "- Simple supervised machine learning classifier\n",
    "- Assumes the features are independent\n",
    "  - Example -- apple is red, round and 4 cm in diameter\n",
    "\n",
    "\n",
    "### Support Vector Machine (SVM)\n",
    "- Another supervised machine learning classifier\n",
    "  - use for both classification and regression\n",
    "- Can do non-linear classification\n",
    "- Hyper plane -- maximize the margin between two classes\n",
    "- Support Vectors -- data points that define the hyper plane\n",
    "- Margin width -- define an optimal hyper plane we need to maximize the width\n",
    "of the margin\n",
    "- Illustration: https://cs.stanford.edu/~karpathy/svmjs/demo/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}